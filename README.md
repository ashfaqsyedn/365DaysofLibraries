# 365DaysofLibraries
Day 1 -- Obsei <br />
  Description: An Open Source AI powered automation tools.<br />
  Official Site: https://obsei.com/. <br />
  Github Site: https://github.com/obsei/obsei. <br />

Day 2 -- Model Store <br />
  Description: Machine Learning library to version, export, save and download ml models in choice of storage. <br />
  Official Site: <br />
  Github Site: https://github.com/operatorai/modelstore. <br />

Day 3 -- Chassis <br />
  Description: Turns ML Models into production contatiners. <br />
  Official Site: https://chassis.ml/ <br />
  Github Site: https://github.com/modzy/chassis <br />
  
Day 4 -- Zingg <br />
  Description: Open Source Identity resolution for single source of truth.<br />
  Official Site: https://www.zingg.ai/ <br />
  Github Site: https://github.com/zinggAI/zingg <br />
  
Day 5 -- Whylogs <br />
  Description: Open Standard for data logging<br />
  Official Site: https://whylabs.ai/whylogs <br />
  Github link: https://github.com/whylabs/whylogs <br />

Day 6 -- Evidently AI <br />
  Description: ML Monitoring, Build tools to evaluate, test and monitor machine learning models.<br />
  Official Site: https://www.evidentlyai.com/ <br />
  Github link: https://github.com/evidentlyai/evidently <br />
  
Day 7 -- Flare, Checkpoint and Bridge <br />
  Description: Bridge- Continuous Deployement from MLFLow, Deploys models from MLFLow to localhost/Sagemaker. Turns your registry into declarative source of truth.; Flare- Monitor models and get alerts without capturing, stoing or processing production inference data. ; Checkpoint- Pull request for ml models for better governance of model deployments.<br />
  Officiail Site: <br />
  Github Link: https://github.com/dominodatalab/domino-research <br />
  
Day 8 -- Grouparoo <br />
  Description: Data synchronisation tool that helps to move data between data warehouses and all of data cloud tools.<br />
  Official Site: https://www.grouparoo.com/ <br />
  Github Link: https://github.com/grouparoo/grouparoo <br />

Day 9 -- FuseML <br />
  Description: Integrating various ml tools for mlops operations. Coherent stack of AI/ML tools to run ml operations.<br />
  Official Site: https://fuseml.github.io/ <br/>
  Github Link:  https://github.com/fuseml/fuseml <br />
  
Day 10 -- Flyte <br />
  Description: Kubernetes-native workflow automation platform for complex, mission-critical data and ML processes at scale.<br />
  Official Site: https://flyte.org/<br />
  Github Link : https://github.com/flyteorg/flyte<br />

Day 11 -- Crane <br />
  Description: <br />
  Official Site: <br />
  Github Link: <br />
  
Day 12 -- Growthbook <br />
  Description: Open source feature flagging and A/B testing. <br />
  Official Site: https://www.growthbook.io/ <br />
  Github Link: https://github.com/growthbook/growthbook <br />
  
Day 13 -- Pandera <br />
  Description: A data validation library for scientists, engineers, and analysts seeking correctness.<br />
  Official Site: https://pandera.readthedocs.io/en/stable/<br />
  Github Link: https://github.com/unionai-oss/pandera <br />
  
Day 14 -- PrimeHub <br />
  Description: Speed up mlops process. Provides cluster computing, one-click research environments, easy dataset loading and management of various types of resources and access control.<br />
  Official Site: https://www.infuseai.io/primehub-ai-platform <br />
  Github Link: https://github.com/InfuseAI/primehub <br />
  
Day 15 -- Orchest <br />
  Description: Build data pipelines the easy way. <br />
  Official Site: https://www.orchest.io/ <br />
  Github Link: https://github.com/orchest/orchest <br />
  
Day 16 -- Lineapy <br />
  Description: Capture analyse and transform messy notebooks into data pipelines <br />
  Official Site: https://lineapy.org/ <br />
  Github Site: https://github.com/LineaLabs/lineapy
  
Day 17 -- Castled.io <br />
  Description: Run real time marketing campaigns on top of your datawarehouse. <br />
  Official Site: https://www.castled.io/ <br />
  Github Site: https://github.com/castledio <br />
  
Day 18 -- Daft  <br />
  Description: Distributed Dataframe for complex data <br/>
  Official Site: https://www.getdaft.io/ <br />
  Github Site: https://github.com/Eventual-Inc/Daft <br />
  
Day 19 -- Pipedream  <br />
  Description: Allows developers to connect many different applications, data sources and api's in order to build useful automated cross-platform workflows.<br/>
  Official Site: https://pipedream.com/ <br />
  Github Site: https://github.com/PipedreamHQ/pipedream <br />

Day 20 -- Dolthub <br />
  Description: SQL Database that supports clone, brannch and merge.<br/>
  Official Site: https://www.dolthub.com/ <br />
  Github Site: <br />
 
Day 21 -- Zarr <br />
  Description: File storage format for chunked, compressed, N - Dimensional Array. <br />
  Official Site: https://zarr.readthedocs.io/en/stable/ <br />
  Github Site: https://github.com/zarr-developers/zarr-python <br />
  
Day 22 -- ray.ai <br />
  Description: GPU Orchestration platform. <br />
  Official Site: https://run.ai  <br />
  Github Site: https://github.com/run-ai <br />
  
Day 23 -- Hugging Face Optimum  <br />
  Description: extension of transformers providing a set of optimization tools enabling maximum efficiency to run and train models. <br />
  Official Site: https://huggingface.co/docs/optimum/index  <br />
  Github Site: https://github.com/huggingface/optimum <br />
  
Day 24 -- Graphcore  <br />
  Description: Build and Deploy AI solutions and Generative AI products using IPU<br />
  Official Site: https://www.graphcore.ai/  <br />
  Github Site: https://github.com/huggingface/optimum-graphcore <br />
  
Day 25 -- Habana  <br />
  Description: Build and Deploy AI solutions and Generative AI products using IPU<br />
  Official Site: https://developer.habana.ai/  <br />
  Github Site: https://github.com/huggingface/optimum-habana  <br />
  
Day 26 -- tdda  <br />
  Description: Tdda allows us to generate constraints from a reference data asset and verify whether another data asset matches those constraints. llows specifying and verifying constraints in data, provides some lightweight profiling.<br />
  Official Site: https://www.tdda.info/  <br />
  Github Site: https://github.com/tdda/tdda <br />
  
Day 27 -- Pandas Profiling  <br />
  Description: Provide one line EDA solution in consistent and fast manner. A.<br />
  Official Site:https://pypi.org/project/pandas-profiling/  <br />
  Github Site: <br />
  
Day 28 -- Ydata Profiling  <br />
  Description: Build and Deploy AI solutions and Generative AI products using IPU<br />
  Official Site: https://ydata-profiling.ydata.ai/docs/master/index.html  <br />
  Github Site: https://github.com/ydataai/ydata-profiling <br />
  
Day 29 -- PyDQC <br />
  Description: Does some data profiling(shows basic stats about a table), compares columns between tables, compares tables for identity. <br />
  Official Site: https://pypi.org/project/pydqc/  <br />
  Github Site: https://github.com/SauceCat/pydqc  <br />

Day 30 -- Great Expectations <br />
  Description: Allows you to write declarative data tests, get validation results from those tests and output a report that documents the current state of your data. <br />
  Official Site : https://greatexpectations.io/ <br />
  Github Site : https://github.com/great-expectations/great_expectations <br />

Day 31 -- Bulwark <br />
  Description: Data testing framework that lets you add test on methods that return pandas dataframes. Has built-in tests and allows custom methods for tests. <br />
  Official Site : https://pypi.org/project/bulwark/ <br />
  Github Site : https://github.com/ZaxR/bulwark <br />

Day 32 -- Engarde <br />
  Description: A precursor to bulwark, allows you to add decorators with data assertions to method that return pandas data frames. <br />
  Official Site : https://engarde.readthedocs.io/en/latest/ <br />
  Github Site : https://github.com/engarde-dev/engarde <br />

Day 33 -- Voluptuous <br />
  Description: Specify a schema to validate JSON/YAML. <br />
  Official Site : <br />
  Github Site : https://github.com/alecthomas/voluptuous <br />
  
Day 34 -- Opulent Pandas <br />
  Description: A df-focused version of Voluptuous. <br />
  Official Site : https://pypi.org/project/bulwark/ <br />
  Github Site : https://github.com/ZaxR/bulwark <br />

Day 35 -- Bulwark <br />
  Description: Data testing framework that lets you add test on methods that return pandas dataframes. Has built-in tests and allows custom methods for tests. <br />
  Official Site : https://pypi.org/project/bulwark/ <br />
  Github Site : https://github.com/ZaxR/bulwark <br />
  
Day 36 -- Mobydq <br />
  Description: Tool to automate data quality checks on their data pipeline, capture data quality issues and trigger alerts in case of anomaly, regardless of data sources they use. <br />
  Official Site : https://ubisoft.github.io/mobydq/ <br />
  Github Site : https://github.com/ubisoft/mobydq <br />
  
Day 37 -- Dedupe <br />
  Description: Using fuzzy matching to perform de-duplication and entity resolution in data. <br />
  Official Site : https://dedupe.io/, https://pypi.org/project/dedupe/ <br />
  Github Site : https://github.com/dedupeio/dedupe <br />
  
Day 38 -- Datacleaner <br />
  Description: A Python tool that automatically cleans data sets and readies them for analysis. <br />
  Official Site : https://pypi.org/project/datacleaner/,  https://pypi.org/project/datacleaner/<br />
  Github Site : https://dbmstools.com/tools/data-cleaner <br />
  
Day 39 -- PyJanitor <br />
  Description : Clean pandas dataframe. <br />
  Official Site : https://pypi.org/project/pyjanitor/, https://pyjanitor-devs.github.io/pyjanitor/ <br />
  Github Site : 
  
Day 40 -- Helm <br />
  Description : Holistic Evaluation of Language Models <br />
  Official Site : https://crfm.stanford.edu/helm/latest/ <br />
  Github Site : https://github.com/stanford-crfm/helm <br />
  
Day 41 -- LLamaHub <br />
  Description : Connect custom data sources to your LLM with one or more of loaders (via LlamaIndex or LangChain) <br />
  Official Site : https://llamahub.ai/ <br />
  Github Site : https://github.com/emptycrown/llama-hub <br />
  
Day 42 -- LlamaLab <br />
  Description : Build cutting edge projects using LLamaIndex.<br />
  Official Site : <br />
  Github Site : https://github.com/run-llama/llama-lab <br />
  
Day 43 -- Cognosis <br />
  Description : Contains an application server and all the infrastructure you need to build LLM's with batteries included. <br />
  Official Site : https://cognosis.ai/ <br />
  Github Site : https://github.com/cognosisai/platform <br />
  
Day 44 -- Dust <br />
  Description : Make and Deploy LLM apps. Build powerful workflows on top of LLMs and Semantic Search<br />
  Official Site : https://dust.tt/ <br />
  Github Site : https://github.com/dust-tt/dust <br />
  
Day 45 -- Fixie <br />
  Description : The automation platform for Large Language Models Build natural language agents that connect to your data, talk to APIs, and solve complex problems. <br />
  Official Site : https://www.fixie.ai/ <br />
  Github Site : https://github.com/fixie-ai/fixie-examples <br />
  
Day 46 -- ChromaDB <br />
  Description : Build cutting edge projects using LLamaIndex.<br />
  Official Site : Open Ending OpenSource Embedding DB.<br />
  Github Site : https://github.com/chroma-core/chroma <br />
  
Day 47 -- qDrant <br />
  Description : Vector Databse<br />
  Official Site : https://qdrant.tech/<br />
  Github Site :https://github.com/qdrant/qdrant <br />
  
Day 48 -- Milvus <br />
  Description : Cloud Native Vector Database<br />
  Official Site : https://milvus.io/ <br />
  Github Site : https://github.com/milvus-io/milvus <br />
  
Day 49 -- Pinecone <br />
  Description : Large scale Vector Database<br />
  Official Site : https://www.pinecone.io/<br />
  Github Site : https://github.com/pinecone-io <br />
  
Day 50 -- Humanloop <br />
  Description : Platform for GPT-4 applications<br />
  Official Site : https://humanloop.com/ <br />
  Github Site : https://github.com/humanloop <br />
  
Day 51 -- honeyhive <br />
  Description : Optimization platform for LLM apps. Continuously improve apps with observability, evaluation, model management and fine tuning tools. <br />
  Official Site :https://honeyhive.ai/ <br />
  Github Site : <br />

Day 52 -- Guardrails <br />
  Description : Guardrails is a Python package that lets a user add structure, type and quality guarantees to the outputs of large language models (LLMs). <br />
  Official Site :  https://shreyar.github.io/guardrails/ <br />
  Github Site :  https://github.com/ShreyaR/guardrails <br />  

Day 53 -- Ecco <br />
  Description : Exploring and Explaining NLP models with visualization.<br />
  Official Site : https://ecco.readthedocs.io/en/main/<br />
  Github Site : https://github.com/jalammar/ecco <br />
  
Day 54 -- Alpa <br />
  Description : Training and scaling large scale neural networks.<br />
  Official Site : <br />
  Github Site : https://github.com/alpa-projects/alpa <br />
  
Day 55 -- openai/shap-e <br />
  Description : Generate 3D objects conditioned on text or images.<br />
  Official Site : <br />
  Github Site : https://github.com/openai/shap-e <br />
  
Day 56 -- SHERPA <br />
  Description : Hyperparamter Optimization of ML Models.<br />
  Official Site : https://sherpa.readthedocs.io/en/4.15.0/, https://parameter-sherpa.readthedocs.io/en/latest/<br />
  Github Site :  <br />
  
Day 57 -- Towhee <br />
  Description : Towhee is an open-source machine learning pipeline
that helps you encode your unstructured data into embeddings.<br />
  Official Site :https://docs.towhee.io/Getting%20Started/quick-start/ <br />
  Github Site :  https://github.com/towhee-io/towhee  <br />
  
Day 58 -- piperider.io <br />
  Description : The Open-Source Data Reliability Toolkit for dbt Projects<br />
  Official Site :https://www.piperider.io/ <br />
  Github Site : https://github.com/InfuseAI/piperider<br />
  
Day 59 -- Alibi-Detect <br />
  Description : Alibi Detect is an open source Python library focused on outlier, adversarial and drift detection. The package aims to cover both online and offline detectors for tabular data, text, images and time series. Both TensorFlow and PyTorch backends are supported for drift detection.<br />
  Official Site : https://docs.seldon.io/projects/alibi-detect/en/stable/ <br />
  Github Site : https://github.com/SeldonIO/alibi-detect <br />

Day 60 -- Metaflow <br />
  Description : Metaflow is a human-friendly Python library that makes it straightforward to develop, deploy, and operate various kinds of data-intensive applications, in particular those involving data science and ML. <br />
  Official Site : https://docs.metaflow.org/ <br />
  Github Site : https://github.com/Netflix/metaflow <br />

Day 61 -- JupySQL <br />
  Description : The Open-Source Data Reliability Toolkit for dbt Projects<br />
  Official Site :https://ploomber.io/blog/jupysql/<br />
  Github Site : https://github.com/ploomber/jupysql<br />

Day 62 -- Hamilton <br />
  Description : a novel paradigm for specifying a flow of delayed execution in python. It was originally built to simplify the creation of wide (1000+) column dataframes, but works on python objects of any type and dataflows of any complexity.
 <br />
Official Site :https://hamilton.dagworks.io/en/latest//<br />
Github Site:  https://github.com/DAGWorks-Inc/hamilton
Other: https://www.tryhamilton.dev/

Day 63 -- Phoenix <br />
  Description : Phoenix provides MLOps insights at lightning speed with zero-config observability for model drift, performance, and data quality<br />
  Official Site  https://docs.arize.com/phoenix/<br />
  Github Site : https://github.com/Arize-ai/phoenix <br />

Day 64 -- Quix Streams <br />
  Description :: a cloud-native library for processing data in Kafka using pure Python. <br />
  Official Site : https://quix-2023.webflow.io/ <br />
  Github Site : https://github.com/quixio/quix-streams

Day 65 -- Dash <br />
  Description :  Python framework for building ML & data science web apps.<br />
  Official Site : https://dash.plotly.com/tutorial <br />
  Github Site :  https://github.com/plotly/dash <br />

Day 66 -- Outerbounds <br />
  Description : Infrastructure for ML , AI and DataScience<br />
  Official Site  https://outerbounds.com//<br />
  Github Site : https://github.com/outerbounds

Day 67 -- dstack.ai <br />
  Description : Make it easy for ML Teams to automate running dev environments and tasks in their cloud<br />
  Official Site https://dstack.ai/<br />
  Github Site : https://github.com/dstackai/dstack<br />
  
Day 68 -- Mage <br />
  Description : Building and deploying data pipelines<br />
  Official Site  https://www.mage.ai/<br />
  Github Site :  https://github.com/mage-ai/mage-ai<br />

Day 69 -- Dozer:  <br />
  Description : Dozer: connect any data source, combine them in real-time and instantly get low-latency data APIs.<br />
  Official Site  https://getdozer.io/<br />
  Github Site :  : https://github.com/getdozer/dozer<br />

Day 70 -- Autolabel <br />
  Description : Autolabel: Access to large, clean, and diverse labeled datasets is a critical component for any machine learning effort to be successful. State-of-the-art LLMs like GPT-4 are able to automatically label data with high accuracy, and at a fraction of the cost and time compared to manual labeling.<br />
  Official Site  : https://docs.refuel.ai//<br />
  Github Site : : https://github.com/refuel-ai/autolabel<br />

Day 71 -- dlt <br />
  Description : an open source Python library that makes data loading easy<br />
  Official Site  https://dlthub.com/<br />
  Github Site :  https://github.com/dlt-hub/dlt<br />

Day 72 -- Determined <br />
  Description : a deep-learning platform that simplifies distributed training, hyperparameter tuning, experiment tracking, and resource management.<br />
  Official Site : https://www.determined.ai/<br />
  Github Site :  https://github.com/determined-ai/determined<br />

Day 73 -- CNDI <br />
  Description : CNDI: a tool with which to deploy GitOps enabled Kubernetes application clusters on any platform as quickly and easily as possible. The best way to understand this process is to look at it as a lifecycle.<br />
  Official Site : https://cndi.dev<br />
  Github Site :  https://github.com/polyseam/cndi<br />

Day 74 -- CrateDB <br />
  Description : CrateDB: a distributed and scalable SQL database for storing and analyzing massive amounts of data in near real-time, even with complex queries
<br />
  Official Site : https://cratedb.com/<br />
  Github Site :  https://github.com/crate/crate<br />

Day 75 -- SuperDuperDB <br />
  Description : an open-source framework for integrating AI directly with your existing databases, including streaming inference, scalable model training, and vector search. <br />
  Official Site : https://www.superduperdb.com/<br />
  Github Site : https://github.com/SuperDuperDB/superduperdb <br />

Day 76 -- Timeplus Proton <br />
  Description : a SQL database for both historical and streaming data, with a strong focus on simplicity, performance, and openness. Written in C++. Powered by ClickHouse.<br />
  Official Site : https://github.com/timeplus-io <br/>
  Github Site :  https://github.com/timeplus-io/proton<br/>

Day 77 -- Encord active <br />
  Description : Encord Active: an open-source toolkit to test, validate, and evaluate your models. Surface, curate, and prioritize the most valuable data for labeling to supercharge model performance. <br />
  Official Site : https://docs.encord.com/ <br />
  Github Site : https://github.com/encord-team/encord-active <br />

Day 78 -- Fluvio <br />
  Description : Fluvio: a lightweight high-performance distributed data streaming system written in Rust and Web Assembly. <br />
  Official Site : https://github.com/infinyon/fluvio <br /> 
  Github Site : https://github.com/infinyon/fluvio <br />
Day 79 -- Composer <br />
  Description : Composer: Built on top of PyTorch, the Composer library makes it easier to implement distributed training workflows on large-scale clusters.<br />
  Official Site :  <br />
  Github Site: https://github.com/mosaicml/composer <br />
Day 80 : FiftyOne <br/>
  Description : FiftyOne is the open source toolkit for building high-quality datasets and computer vision models. <br />
  Official Site : https://voxel51.com/fiftyone/ <br />
  Github Site: https://github.com/voxel51/fiftyone <br />
Day 81: Probabl.ai <br/>
  Description : Open Source Commons for AI, Machine Learning, and Data Science. <br />
  Official Site : https://probabl.ai/ <br />
  Github Site : https://github.com/probabl-ai <br />
Day 82: JuiceFS <br/>
  Description: A High-Performance, Cloud-Native, Distributed File System Elastic, Multi-Cloud, Compatible with POSIX, HDFS, and S3 Protocols. <br />
  Official Site : https://juicefs.com/en/ <br />
  Github Site : https://github.com/juicedata/juicefs <br/>


